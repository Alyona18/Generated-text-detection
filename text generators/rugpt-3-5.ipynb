{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8198681,"sourceType":"datasetVersion","datasetId":4856683},{"sourceId":8414446,"sourceType":"datasetVersion","datasetId":4972843}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport torch\nfrom transformers import Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n\noperations_ids = []\nprev_titles = []","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:42:13.842172Z","iopub.execute_input":"2024-05-27T10:42:13.842517Z","iopub.status.idle":"2024-05-27T10:42:13.849265Z","shell.execute_reply.started":"2024-05-27T10:42:13.842490Z","shell.execute_reply":"2024-05-27T10:42:13.848385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"news_dataset = pd.read_csv('/kaggle/input/news-for-df/Lenta_dataset.csv')\nnews_dataset.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-27T10:42:20.470507Z","iopub.execute_input":"2024-05-27T10:42:20.470890Z","iopub.status.idle":"2024-05-27T10:43:10.891402Z","shell.execute_reply.started":"2024-05-27T10:42:20.470861Z","shell.execute_reply":"2024-05-27T10:43:10.890437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"safe_df = news_dataset[~news_dataset['tags'].isin(['Все','Политика', 'Первая мировая', 'Россия', 'Вооружение', 'Выборы', 'Киберпреступность','Украина', 'Молдавия', 'Преступная Россия', 'Полиция и спецслужбы', 'Конфликты', 'Преступность', 'Криминал', 'Оружие', 'Следствие и суд'])]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:43:10.893143Z","iopub.execute_input":"2024-05-27T10:43:10.893479Z","iopub.status.idle":"2024-05-27T10:43:10.982223Z","shell.execute_reply.started":"2024-05-27T10:43:10.893442Z","shell.execute_reply":"2024-05-27T10:43:10.981124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = safe_df.sample(1000)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:43:27.355782Z","iopub.execute_input":"2024-05-27T10:43:27.356152Z","iopub.status.idle":"2024-05-27T10:43:27.372862Z","shell.execute_reply.started":"2024-05-27T10:43:27.356120Z","shell.execute_reply":"2024-05-27T10:43:27.371793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2024-05-25T23:09:15.805963Z","iopub.execute_input":"2024-05-25T23:09:15.806329Z","iopub.status.idle":"2024-05-25T23:09:15.829769Z","shell.execute_reply.started":"2024-05-25T23:09:15.806300Z","shell.execute_reply":"2024-05-25T23:09:15.828776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name = \"ai-forever/rugpt3small_based_on_gpt2\"\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\nmodel = GPT2LMHeadModel.from_pretrained(model_name)\n\nif torch.cuda.is_available():\n    model.cuda()\n\nwith open(\"train_texts.txt\", \"w\", encoding=\"utf-8\") as f:\n    for text in test['text']:\n        f.write(text + \"\\n\")\n\ndef load_dataset(file_path, tokenizer, block_size=128):\n    dataset = TextDataset(\n        tokenizer=tokenizer,\n        file_path=file_path,\n        block_size=block_size\n    )\n    return dataset\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,\n)\n\ntrain_file_path = \"train_texts.txt\"\ntrain_dataset = load_dataset(train_file_path, tokenizer)\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    overwrite_output_dir=True,\n    num_train_epochs=1,\n    per_device_train_batch_size=8,\n    save_steps=100_000,\n    save_total_limit=2,\n    logging_dir='./logs',\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n)\ntrainer.train()\n\nmodel.save_pretrained('./trained_model')\ntokenizer.save_pretrained('./trained_model')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-26T12:19:10.835464Z","iopub.execute_input":"2024-05-26T12:19:10.835799Z","iopub.status.idle":"2024-05-26T12:19:15.596969Z","shell.execute_reply.started":"2024-05-26T12:19:10.835773Z","shell.execute_reply":"2024-05-26T12:19:15.595563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n\ndef load_dataset(file_path, tokenizer, block_size=128):\n    dataset = TextDataset(\n        tokenizer=tokenizer,\n        file_path=file_path,\n        block_size=block_size\n    )\n    return dataset\n\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False,\n)\n\n\ntrain_file_path = \"train_texts.txt\"\ntrain_dataset = load_dataset(train_file_path, tokenizer)\n\nmodel_path = './new_new_trained_model'\ntokenizer = GPT2Tokenizer.from_pretrained(model_path)\nmodel = GPT2LMHeadModel.from_pretrained(model_path)\n\n# Перенос модели на GPU, если доступно\nif torch.cuda.is_available():\n    model.cuda()\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    overwrite_output_dir=True,\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    save_steps=100000,\n    save_total_limit=2,\n    logging_dir='./logs',\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n)\n\ntrainer.train()\n\n\nmodel.save_pretrained('./new_new_new_trained_model')\ntokenizer.save_pretrained('./new_new_new_trained_model')","metadata":{"execution":{"iopub.status.busy":"2024-05-26T18:42:08.342291Z","iopub.execute_input":"2024-05-26T18:42:08.342662Z","iopub.status.idle":"2024-05-26T21:12:41.487850Z","shell.execute_reply.started":"2024-05-26T18:42:08.342632Z","shell.execute_reply":"2024-05-26T21:12:41.486842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_result = pd.DataFrame(columns=['title', 'generated_text'])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:43:55.184993Z","iopub.execute_input":"2024-05-27T10:43:55.185899Z","iopub.status.idle":"2024-05-27T10:43:55.191975Z","shell.execute_reply.started":"2024-05-27T10:43:55.185869Z","shell.execute_reply":"2024-05-27T10:43:55.190983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"now_titles = safe_df.title.sample(500)\ntitles =  [x for x in now_titles if x not in prev_titles]\nprev_titles = prev_titles + titles","metadata":{"execution":{"iopub.status.busy":"2024-05-27T13:51:20.283159Z","iopub.execute_input":"2024-05-27T13:51:20.283761Z","iopub.status.idle":"2024-05-27T13:51:20.306005Z","shell.execute_reply.started":"2024-05-27T13:51:20.283730Z","shell.execute_reply":"2024-05-27T13:51:20.305098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load model directly\n#from transformers import AutoTokenizer, AutoModelForCausalLM\n#from transformers import AutoModel\n\n\nmodel_path = './new_new_new_trained_model'\ntokenizer = GPT2Tokenizer.from_pretrained(model_path)\nmodel = GPT2LMHeadModel.from_pretrained(model_path)\n#tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\n#model = AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3small_based_on_gpt2\")\nif torch.cuda.is_available():\n    model = model.cuda() ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T10:44:10.297163Z","iopub.execute_input":"2024-05-27T10:44:10.297522Z","iopub.status.idle":"2024-05-27T10:44:10.997556Z","shell.execute_reply.started":"2024-05-27T10:44:10.297495Z","shell.execute_reply":"2024-05-27T10:44:10.996358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_text(prompt, model, tokenizer,  max_length=1000):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    encoded_input = tokenizer.encode(prompt, return_tensors='pt').to(device)\n    \n    output_sequences = model.generate(\n        input_ids=encoded_input,\n        max_length=max_length,\n        temperature=0.7,\n        no_repeat_ngram_size=2,\n        do_sample=True,\n        top_k=50,\n        top_p=0.95,\n        num_return_sequences=1\n    )\n\n    text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n    end_pos = text.rfind('.')\n    if end_pos != -1:\n        text = text[:end_pos+1]\n    return text\n\n\ngenerated = []\nfor title in titles[400:]:\n    prompt_text = f\"Новостная статья: {title}\"\n    generated_text = generate_text(prompt_text, model, tokenizer, max_length=500)\n    generated.append((title, generated_text))\n\ntmp = pd.DataFrame(generated, columns=['title','generated_text'])\ngenerated_result = pd.concat([generated_result, tmp])\ngenerated_result = generated_result.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T16:36:22.997529Z","iopub.execute_input":"2024-05-27T16:36:22.997921Z","iopub.status.idle":"2024-05-27T16:46:43.699709Z","shell.execute_reply.started":"2024-05-27T16:36:22.997889Z","shell.execute_reply":"2024-05-27T16:46:43.698854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_result","metadata":{"execution":{"iopub.status.busy":"2024-05-27T16:46:43.701298Z","iopub.execute_input":"2024-05-27T16:46:43.701597Z","iopub.status.idle":"2024-05-27T16:46:43.713297Z","shell.execute_reply.started":"2024-05-27T16:46:43.701572Z","shell.execute_reply":"2024-05-27T16:46:43.712292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = pipeline(model=\"ai-forever/mGPT\", max_length=500)\ngenerator(f\"{titles[0]}.\", do_sample=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_result.to_csv('/kaggle/working/generated_rugpt3_pre_trained_small.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T16:46:43.714563Z","iopub.execute_input":"2024-05-27T16:46:43.714851Z","iopub.status.idle":"2024-05-27T16:46:43.948217Z","shell.execute_reply.started":"2024-05-27T16:46:43.714825Z","shell.execute_reply":"2024-05-27T16:46:43.947300Z"},"trusted":true},"execution_count":null,"outputs":[]}]}