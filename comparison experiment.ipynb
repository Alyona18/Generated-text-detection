{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8513543,"sourceType":"datasetVersion","datasetId":5082315},{"sourceId":8516265,"sourceType":"datasetVersion","datasetId":5041224},{"sourceId":53826,"sourceType":"modelInstanceVersion","modelInstanceId":45139},{"sourceId":54126,"sourceType":"modelInstanceVersion","modelInstanceId":45383},{"sourceId":54133,"sourceType":"modelInstanceVersion","modelInstanceId":45388}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import DistilBertTokenizer,DistilBertConfig, DistilBertForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import accuracy_score, recall_score, roc_auc_score, f1_score\nfrom sklearn.metrics import roc_curve, auc\nimport torch\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nfrom transformers import TrainerCallback\nfrom torch.utils.data import DataLoader\n\n#torch.cuda.set_per_process_memory_fraction(device=0, fraction=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:59:26.833882Z","iopub.execute_input":"2024-05-25T16:59:26.834238Z","iopub.status.idle":"2024-05-25T16:59:26.840410Z","shell.execute_reply.started":"2024-05-25T16:59:26.834209Z","shell.execute_reply":"2024-05-25T16:59:26.839476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config_rubert = DistilBertConfig.from_pretrained(\"DeepPavlov/distilrubert-tiny-cased-conversational\")\nmodel_state_rubert = torch.load(\"/kaggle/input/rubert-pre-trained/pytorch/v1/1/model_distilrubert_latest.pth\")\n\n# Создание экземпляра модели\nmodel_trained_rubert = DistilBertForSequenceClassification(config_rubert)\n\n# Установка состояния модели из загруженного файла\nmodel_trained_rubert.load_state_dict(model_state_rubert)\ntokenizer_rubert = DistilBertTokenizer.from_pretrained(\"DeepPavlov/distilrubert-tiny-cased-conversational\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-25T16:59:28.574848Z","iopub.execute_input":"2024-05-25T16:59:28.575303Z","iopub.status.idle":"2024-05-25T16:59:37.834239Z","shell.execute_reply.started":"2024-05-25T16:59:28.575268Z","shell.execute_reply":"2024-05-25T16:59:37.833211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaForSequenceClassification,RobertaConfig\n\nconfig_roberta = RobertaConfig.from_pretrained(\"blinoff/roberta-base-russian-v0\")\nmodel_state_roberta = torch.load(\"/kaggle/input/roberta-pre-traind/pytorch/v1/1/model_roberta_latest.pth\")\n\n# Создание экземпляра модели\nmodel_trained_roberta = RobertaForSequenceClassification(config_roberta)\n\n# Установка состояния модели из загруженного файла\nmodel_trained_roberta.load_state_dict(model_state_roberta)\ntokenizer_roberta = RobertaTokenizer.from_pretrained(\"blinoff/roberta-base-russian-v0\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:59:37.836198Z","iopub.execute_input":"2024-05-25T16:59:37.836565Z","iopub.status.idle":"2024-05-25T16:59:48.901258Z","shell.execute_reply.started":"2024-05-25T16:59:37.836529Z","shell.execute_reply":"2024-05-25T16:59:48.900286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DebertaTokenizer, DebertaForSequenceClassification, DebertaConfig\n\nconfig_deberta = DebertaConfig.from_pretrained(\"deepvk/deberta-v1-distill\")\nmodel_state_deberta = torch.load(\"/kaggle/input/deberta-pre-trained/pytorch/v1/1/model_deberta_v2.pth\")\n\n# Создание экземпляра модели\nmodel_trained_deberta = DebertaForSequenceClassification(config_deberta)\n\n# Установка состояния модели из загруженного файла\nmodel_trained_deberta.load_state_dict(model_state_deberta)\ntokenizer_deberta = DebertaTokenizer.from_pretrained(\"deepvk/deberta-v1-distill\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T16:59:48.902472Z","iopub.execute_input":"2024-05-25T16:59:48.902781Z","iopub.status.idle":"2024-05-25T16:59:56.449403Z","shell.execute_reply.started":"2024-05-25T16:59:48.902756Z","shell.execute_reply":"2024-05-25T16:59:56.448584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/cooked-shorter-small/cooked_dataset_cutted_small.csv\")  \ntexts = df[\"clean_text\"].tolist()\nlabels = df[\"generated\"].tolist()\n\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n    \nencodings_rubert = tokenizer_rubert(texts, truncation=True, padding=True, max_length=512)\nencodings_roberta = tokenizer_roberta(texts, truncation=True, padding=True)\nencodings_deberta = tokenizer_deberta(texts, truncation=True, padding=True)\n\n\ndataset_rubert = CustomDataset(encodings_rubert, labels)\ndataset_roberta = CustomDataset(encodings_roberta, labels)\ndataset_deberta = CustomDataset(encodings_deberta, labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:15:56.307695Z","iopub.execute_input":"2024-05-25T18:15:56.308115Z","iopub.status.idle":"2024-05-25T18:18:20.589372Z","shell.execute_reply.started":"2024-05-25T18:15:56.308086Z","shell.execute_reply":"2024-05-25T18:18:20.588314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ndataloader = DataLoader(dataset_roberta, batch_size=batch_size)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel_trained_roberta = model_trained_roberta.to(device)\nmodel_trained_roberta.eval()\n\n\ntrue_labels = []\npredicted_labels = []\nlogits = []\nwith torch.no_grad():\n    for batch in dataloader:\n        input_ids = batch['input_ids'].to(device)  # Предположим, что input_ids находится на нулевой позиции в батче\n        attention_mask = batch['attention_mask'].to(device)  # Предположим, что attention_mask находится на первой позиции в батче\n        outputs = model_trained_roberta(input_ids, attention_mask=attention_mask)\n        predictions = torch.argmax(outputs.logits, dim=1)\n        predicted_labels.extend(predictions.detach().cpu().numpy())\n        true_labels.extend(batch['labels'])\n        logits.extend(outputs.logits)\n\nprint(len(true_labels), ' ', len(predicted_labels))\n\n\nassert len(true_labels) == len(predicted_labels), \"Количество истинных меток не совпадает с количеством предсказанных меток\"\n\nif len(true_labels) == len(predicted_labels):\n    accuracy = accuracy_score(true_labels, predicted_labels)\n    recall = recall_score(true_labels, predicted_labels)\n    auc_score = roc_auc_score(true_labels, predicted_labels)\n    f1 = f1_score(true_labels, predicted_labels)\n    print(\"Accuracy:\", accuracy)\n    print(\"Recall:\", recall)\n    print(\"ROC AUC:\", auc_score)\n    print(\"F1 score:\", f1)\nelse:\n    print(\"Количество истинных меток не совпадает с количеством предсказанных меток.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:22:30.500962Z","iopub.execute_input":"2024-05-25T18:22:30.501294Z","iopub.status.idle":"2024-05-25T18:44:37.121523Z","shell.execute_reply.started":"2024-05-25T18:22:30.501268Z","shell.execute_reply":"2024-05-25T18:44:37.120579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ndataloader = DataLoader(dataset_rubert, batch_size=batch_size)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel_trained_rubert = model_trained_rubert.to(device)\nmodel_trained_rubert.eval()\n\n\ntrue_labels_rubert = []\npredicted_labels_rubert = []\nlogits_rubert = []\nwith torch.no_grad():\n    for batch in dataloader:\n        input_ids = batch['input_ids'].to(device)  # Предположим, что input_ids находится на нулевой позиции в батче\n        attention_mask = batch['attention_mask'].to(device)  # Предположим, что attention_mask находится на первой позиции в батче\n        outputs = model_trained_rubert(input_ids, attention_mask=attention_mask)\n        predictions = torch.argmax(outputs.logits, dim=1)\n        predicted_labels_rubert.extend(predictions.detach().cpu().numpy())\n        true_labels_rubert.extend(batch['labels'])\n        logits_rubert.extend(outputs.logits)\n\nprint(len(true_labels_rubert), ' ', len(predicted_labels_rubert))\n\n\nassert len(true_labels_rubert) == len(predicted_labels_rubert), \"Количество истинных меток не совпадает с количеством предсказанных меток\"\n\nif len(true_labels_rubert) == len(predicted_labels_rubert):\n    accuracy = accuracy_score(true_labels_rubert, predicted_labels_rubert)\n    recall = recall_score(true_labels_rubert, predicted_labels_rubert)\n    auc_score = roc_auc_score(true_labels_rubert, predicted_labels_rubert)\n    f1 = f1_score(true_labels_rubert, predicted_labels_rubert)\n    print(\"Accuracy:\", accuracy)\n    print(\"Recall:\", recall)\n    print(\"ROC AUC:\", auc_score)\n    print(\"F1 score:\", f1)\nelse:\n    print(\"Количество истинных меток не совпадает с количеством предсказанных меток.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:44:37.123359Z","iopub.execute_input":"2024-05-25T18:44:37.123650Z","iopub.status.idle":"2024-05-25T18:48:52.204160Z","shell.execute_reply.started":"2024-05-25T18:44:37.123624Z","shell.execute_reply":"2024-05-25T18:48:52.203139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ndataloader = DataLoader(dataset_deberta, batch_size=batch_size)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel_trained_deberta = model_trained_deberta.to(device)\nmodel_trained_deberta.eval()\n\n\ntrue_labels_deberta = []\npredicted_labels_deberta = []\nlogits_deberta = []\nwith torch.no_grad():\n    for batch in dataloader:\n        input_ids = batch['input_ids'].to(device)  # Предположим, что input_ids находится на нулевой позиции в батче\n        attention_mask = batch['attention_mask'].to(device)  # Предположим, что attention_mask находится на первой позиции в батче\n        outputs = model_trained_deberta(input_ids, attention_mask=attention_mask)\n        predictions = torch.argmax(outputs.logits, dim=1)\n        predicted_labels_deberta.extend(predictions.detach().cpu().numpy())\n        true_labels_deberta.extend(batch['labels'])\n        logits_deberta.extend(outputs.logits)\n\nprint(len(true_labels_deberta), ' ', len(predicted_labels_deberta))\n\n\nassert len(true_labels_deberta) == len(predicted_labels_deberta), \"Количество истинных меток не совпадает с количеством предсказанных меток\"\n\nif len(true_labels_deberta) == len(predicted_labels_deberta):\n    accuracy = accuracy_score(true_labels_deberta, predicted_labels_deberta)\n    recall = recall_score(true_labels_deberta, predicted_labels_deberta)\n    auc_score = roc_auc_score(true_labels_deberta, predicted_labels_deberta)\n    f1 = f1_score(true_labels_deberta, predicted_labels_deberta)\n    print(\"Accuracy:\", accuracy)\n    print(\"Recall:\", recall)\n    print(\"ROC AUC:\", auc_score)\n    print(\"F1 score:\", f1)\nelse:\n    print(\"Количество истинных меток не совпадает с количеством предсказанных меток.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T18:53:09.745392Z","iopub.execute_input":"2024-05-25T18:53:09.745798Z","iopub.status.idle":"2024-05-25T19:05:46.817899Z","shell.execute_reply.started":"2024-05-25T18:53:09.745767Z","shell.execute_reply":"2024-05-25T19:05:46.816867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/test-cooked/cooked_dataset_test_small.csv\")  \n\ntexts_test = df_test[\"clean_text\"].tolist()\nlabels_test = df_test[\"generated\"].tolist()\n\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\nencodings_rubert_test = tokenizer_rubert(texts_test, truncation=True, padding=True, max_length=512)\nencodings_roberta_test = tokenizer_roberta(texts_test, truncation=True, padding=True)\nencodings_deberta_test = tokenizer_deberta(texts_test, truncation=True, padding=True)\n\n\n\ndataset_rubert_test = CustomDataset(encodings_rubert_test, labels_test)\ndataset_roberta_test = CustomDataset(encodings_roberta_test, labels_test)\ndataset_deberta_test = CustomDataset(encodings_deberta_test, labels_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:05:46.819865Z","iopub.execute_input":"2024-05-25T19:05:46.820189Z","iopub.status.idle":"2024-05-25T19:07:52.477825Z","shell.execute_reply.started":"2024-05-25T19:05:46.820161Z","shell.execute_reply":"2024-05-25T19:07:52.476811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nmodel_trained_roberta\nbatch_size = 8\ndataloader_test = DataLoader(dataset_roberta_test, batch_size=batch_size)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel_trained_roberta = model_trained_roberta.to(device)\nmodel_trained_roberta.eval()\n\n\ntrue_labels_test = []\npredicted_labels_test = []\nlogits_test = []\nwith torch.no_grad():\n    for batch in dataloader_test:\n        input_ids = batch['input_ids'].to(device)  # Предположим, что input_ids находится на нулевой позиции в батче\n        attention_mask = batch['attention_mask'].to(device)  # Предположим, что attention_mask находится на первой позиции в батче\n        outputs = model_trained_roberta(input_ids, attention_mask=attention_mask)\n        predictions = torch.argmax(outputs.logits, dim=1)\n        predicted_labels_test.extend(predictions.detach().cpu().numpy())\n        true_labels_test.extend(batch['labels'])\n        logits_test.extend(outputs.logits)\n\nprint(len(true_labels_test), ' ', len(predicted_labels_test))\n\n\nassert len(true_labels_test) == len(predicted_labels_test), \"Количество истинных меток не совпадает с количеством предсказанных меток\"\n\nif len(true_labels_test) == len(predicted_labels_test):\n    accuracy = accuracy_score(true_labels_test, predicted_labels_test)\n    recall = recall_score(true_labels_test, predicted_labels_test)\n    auc_score = roc_auc_score(true_labels_test, predicted_labels_test)\n    f1 = f1_score(true_labels_test, predicted_labels_test)\n    print(\"Accuracy:\", accuracy)\n    print(\"Recall:\", recall)\n    print(\"ROC AUC:\", auc_score)\n    print(\"F1 score:\", f1)\nelse:\n    print(\"Количество истинных меток не совпадает с количеством предсказанных меток.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:11:40.680792Z","iopub.execute_input":"2024-05-25T19:11:40.681154Z","iopub.status.idle":"2024-05-25T19:17:36.204340Z","shell.execute_reply.started":"2024-05-25T19:11:40.681127Z","shell.execute_reply":"2024-05-25T19:17:36.203450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ndataloader_test = DataLoader(dataset_rubert_test, batch_size=batch_size)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel_trained_rubert = model_trained_rubert.to(device)\nmodel_trained_rubert.eval()\n\n\ntrue_labels_rubert_test = []\npredicted_labels_rubert_test = []\nlogits_rubert_test = []\nwith torch.no_grad():\n    for batch in dataloader_test:\n        input_ids = batch['input_ids'].to(device)  # Предположим, что input_ids находится на нулевой позиции в батче\n        attention_mask = batch['attention_mask'].to(device)  # Предположим, что attention_mask находится на первой позиции в батче\n        outputs = model_trained_rubert(input_ids, attention_mask=attention_mask)\n        predictions = torch.argmax(outputs.logits, dim=1)\n        predicted_labels_rubert_test.extend(predictions.detach().cpu().numpy())\n        true_labels_rubert_test.extend(batch['labels'])\n        logits_rubert_test.extend(outputs.logits)\n\nprint(len(true_labels_rubert_test), ' ', len(predicted_labels_rubert_test))\n\n\nassert len(true_labels_rubert_test) == len(predicted_labels_rubert_test), \"Количество истинных меток не совпадает с количеством предсказанных меток\"\n\nif len(true_labels_rubert_test) == len(predicted_labels_rubert_test):\n    accuracy = accuracy_score(true_labels_rubert_test, predicted_labels_rubert_test)\n    recall = recall_score(true_labels_rubert_test, predicted_labels_rubert_test)\n    auc_score = roc_auc_score(true_labels_rubert_test, predicted_labels_rubert_test)\n    f1 = f1_score(true_labels_rubert_test, predicted_labels_rubert_test)\n    print(\"Accuracy:\", accuracy)\n    print(\"Recall:\", recall)\n    print(\"ROC AUC:\", auc_score)\n    print(\"F1 score:\", f1)\nelse:\n    print(\"Количество истинных меток не совпадает с количеством предсказанных меток.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:24:09.377163Z","iopub.execute_input":"2024-05-25T19:24:09.377898Z","iopub.status.idle":"2024-05-25T19:25:11.784756Z","shell.execute_reply.started":"2024-05-25T19:24:09.377866Z","shell.execute_reply":"2024-05-25T19:25:11.783733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8\ndataloader_test = DataLoader(dataset_deberta_test, batch_size=batch_size)\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nmodel_trained_deberta = model_trained_deberta.to(device)\nmodel_trained_deberta.eval()\n\n\ntrue_labels_deberta_test = []\npredicted_labels_deberta_test = []\nlogits_deberta_test = []\nwith torch.no_grad():\n    for batch in dataloader_test:\n        input_ids = batch['input_ids'].to(device)  # Предположим, что input_ids находится на нулевой позиции в батче\n        attention_mask = batch['attention_mask'].to(device)  # Предположим, что attention_mask находится на первой позиции в батче\n        outputs = model_trained_deberta(input_ids, attention_mask=attention_mask)\n        predictions = torch.argmax(outputs.logits, dim=1)\n        predicted_labels_deberta_test.extend(predictions.detach().cpu().numpy())\n        true_labels_deberta_test.extend(batch['labels'])\n        logits_deberta_test.extend(outputs.logits)\n\nprint(len(true_labels_deberta_test), ' ', len(predicted_labels_deberta_test))\n\n\nassert len(true_labels_deberta) == len(predicted_labels_deberta), \"Количество истинных меток не совпадает с количеством предсказанных меток\"\n\nif len(true_labels_deberta_test) == len(predicted_labels_deberta_test):\n    accuracy = accuracy_score(true_labels_deberta_test, predicted_labels_deberta_test)\n    recall = recall_score(true_labels_deberta_test, predicted_labels_deberta_test)\n    auc_score = roc_auc_score(true_labels_deberta_test, predicted_labels_deberta_test)\n    f1 = f1_score(true_labels_deberta_test, predicted_labels_deberta_test)\n    print(\"Accuracy:\", accuracy)\n    print(\"Recall:\", recall)\n    print(\"ROC AUC:\", auc_score)\n    print(\"F1 score:\", f1)\nelse:\n    print(\"Количество истинных меток не совпадает с количеством предсказанных меток.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T19:25:11.786386Z","iopub.execute_input":"2024-05-25T19:25:11.786736Z","iopub.status.idle":"2024-05-25T19:28:37.808187Z","shell.execute_reply.started":"2024-05-25T19:25:11.786704Z","shell.execute_reply":"2024-05-25T19:28:37.807046Z"},"trusted":true},"execution_count":null,"outputs":[]}]}